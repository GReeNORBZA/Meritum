# D07-021: Service: Tier 1 rule execution — evaluate all rules, generate suggestions, apply learning state

## Project Context
You are building **Meritum Health Technologies**, a self-serve medical billing platform for Alberta physicians (AHCIP + WCB claims). This is a monorepo with:
- `apps/api` — Fastify 5 REST API with Drizzle ORM, PostgreSQL 16
- `apps/web` — Next.js 15 frontend
- `packages/shared` — Shared Drizzle schemas, Zod validators, constants, utilities

Tech stack: TypeScript, Fastify 5, Drizzle ORM, PostgreSQL 16, Vitest + Supertest, Lucia auth.

Read `CLAUDE.md` in the project root for full conventions (naming, structure, error handling, security, testing).

## Dependencies
This task depends on: **D07-020** (condition evaluator and claim context builder).

## What to Build
Add Tier 1 rule execution to `apps/api/src/domains/intel/intel.service.ts`:

- `evaluateTier1Rules(claimId: string, providerId: string)` — main Tier 1 entry point:
  1. Build claim context (D07-020).
  2. Determine claim_type (AHCIP or WCB) and provider specialty.
  3. Fetch active rules for this claim_type and specialty (D07-010).
  4. Batch-fetch learning states for provider + all candidate rules (D07-011).
  5. For each rule:
     a. Check if suppressed for this provider -> skip if suppressed.
     b. Evaluate condition tree against context -> skip if false.
     c. Render suggestion from template: interpolate placeholders, calculate revenue_impact, determine priority (base formula + provider's priority_adjustment).
     d. Set confidence = 1.00 (deterministic), tier = 1.
     e. Record GENERATED event in ai_suggestion_events.
     f. Increment times_shown in learning state.
  6. Deduplicate: if multiple rules produce suggestions for the same field/modifier, keep highest priority.
  7. Sort by priority (HIGH first), then by revenue_impact descending.
  Return: Suggestion[].

- `renderSuggestion(template: SuggestionTemplate, context: ClaimContext, priorityAdjustment: number)` — interpolate template placeholders ({{hsc}}, {{modifier}}, {{fee_difference}}, etc.) with context values. Calculate priority from formula with adjustment.

**Performance:** Tier 1 must complete synchronously within the claim save flow. Target: <100ms for 105 rules against one claim. Rules with cross_claim conditions are the bottleneck — pre-fetch claim history in context builder.

## FRD References
- Domain 7 Section 3.1: Tier 1 runs synchronously, zero latency, zero LLM cost. Section 3.4: MVP rule library ~105 rules across 4 categories.
- Domain 7 Section 6.2: Suppression threshold, priority adjustment, specialty calibration.

## Expected Tests
Add tests in `apps/api/src/domains/intel/intel.test.ts`:
- evaluateTier1Rules returns suggestions for matching rules
- evaluateTier1Rules skips suppressed rules
- evaluateTier1Rules skips inactive rules
- evaluateTier1Rules skips rules not matching claim_type
- evaluateTier1Rules skips rules not matching specialty
- evaluateTier1Rules deduplicates same-field suggestions
- evaluateTier1Rules sorts by priority then revenue_impact
- evaluateTier1Rules records GENERATED events
- evaluateTier1Rules increments times_shown
- renderSuggestion interpolates placeholders correctly
- renderSuggestion applies priority adjustment

## Run After Completion
After completing your changes, run:
```bash
pnpm --filter api vitest run src/domains/intel/intel.test.ts
```
Fix any errors before finishing.
