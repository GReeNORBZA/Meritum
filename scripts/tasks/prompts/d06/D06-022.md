# Task D06-022: Service — CSV bulk import workflow

## Project Context
- Monorepo: Turborepo + pnpm workspaces
- API: `apps/api` (Fastify 5, TypeScript)
- Shared: `packages/shared` (Drizzle schemas, Zod validators, constants)
- DB: PostgreSQL 16 with Drizzle ORM
- Test: Vitest + Supertest
- Auth: Lucia sessions with RBAC middleware from Domain 1
- All queries MUST include physician_id for tenant isolation (HIA custodian boundary)
- PHN is PHI — mask as 123****** in all logs and audit entries

## What to Build

Add to `apps/api/src/domains/patient/patient.service.ts`:

- `initiateImport(physicianId: string, file: Buffer, fileName: string, actorId: string)` — compute SHA-256 hash of file. Check for duplicate upload (same hash for this physician). Parse CSV: auto-detect delimiter (comma, tab, pipe) and header row presence. Create import batch record. Store parsed rows temporarily. Return import_id.

- `getImportPreview(importId: string, physicianId: string)` — return: detected delimiter, detected headers, auto-mapped columns (using the column mapping aliases from constants), first 10 rows with mapped values, validation warnings for preview rows.

- `updateImportMapping(importId: string, physicianId: string, mapping: Record<string, string | null>)` — physician confirms or adjusts the column-to-field mapping.

- `commitImport(importId: string, physicianId: string, actorId: string)` — process all rows:
  1. Set status = PROCESSING.
  2. For each row: validate required fields (first_name, last_name, dob, gender). Validate PHN if present (Luhn). Apply gender mappings (Male->M, Female->F).
  3. Duplicate handling: if PHN match found in physician's patients -> update (non-null import values overwrite). If no match -> create. If no PHN -> always create. If duplicate PHN in file -> skip second occurrence.
  4. Track counts: created, updated, skipped, error. Store per-row error details.
  5. Set status = COMPLETED (or FAILED if entire batch fails).
  6. Emit patient.import_completed audit event with counts.

- `getImportStatus(importId: string, physicianId: string)` — return current status and result counts.

## FRD References

- Domain 6 Section 5.1: Import workflow — upload, detect, map, preview, commit, results.
- Domain 6 Section 5.2: Column mapping with common CSV header aliases.
- Domain 6 Section 5.3: Duplicate handling — PHN match updates, no match creates, no PHN always creates, duplicate in file skips.

## Security Requirements

- CSV files processed in memory. Uploaded files stored temporarily (encrypted), deleted after import completion.
- Import scoped to physician_id — imported patients belong to the initiating physician.
- File hash check prevents accidental duplicate imports.

## Required Tests

Add tests in `apps/api/src/domains/patient/patient.test.ts`:

- initiateImport parses comma-delimited CSV with headers
- initiateImport parses tab-delimited CSV without headers
- initiateImport detects duplicate file upload by hash
- getImportPreview returns auto-mapped columns
- getImportPreview returns first 10 rows with validation warnings
- commitImport creates patients for new rows
- commitImport updates existing patients by PHN match
- commitImport skips duplicate PHN in same file
- commitImport rejects rows with invalid PHN (bad Luhn)
- commitImport rejects rows missing required fields
- commitImport tracks correct created/updated/skipped/error counts
- commitImport emits audit event with counts

## Dependencies

- D06-010 must be complete (patient CRUD repository).
- D06-012 must be complete (CSV import batch repository).

## Run After Completion

```bash
pnpm --filter api vitest run src/domains/patient/patient.test.ts
```

All tests must pass before outputting [TASK_COMPLETE].
